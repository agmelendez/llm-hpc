# ü¶ô LLaMA 3.2 1B ‚Äì Fine-Tuning en Espa√±ol (QLoRA + Unsloth)

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.7.1-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-Academic-green.svg)]()

Fine-tuning eficiente del modelo **LLaMA 3.2 1B Instruct** en espa√±ol usando **QLoRA (4-bit)** con la librer√≠a **Unsloth**, ejecutado en el cluster **HPC-UCR**.

---

## üìã Tabla de Contenidos

- [Descripci√≥n General](#-descripci√≥n-general)
- [Inicio R√°pido](#-inicio-r√°pido)
- [Instalaci√≥n](#-instalaci√≥n)
- [Configuraci√≥n](#-configuraci√≥n)
- [Formato de Datos](#-formato-de-datos)
- [Entrenamiento](#-entrenamiento)
- [Inferencia](#-inferencia)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Resultados](#-resultados)
- [Resoluci√≥n de Problemas](#-resoluci√≥n-de-problemas)
- [Contribuciones](#-contribuciones)
- [Autor](#-autor)

---

## üß† Descripci√≥n General

Este proyecto adapta el modelo **LLaMA 3.2 1B Instruct** al **espa√±ol** utilizando fine-tuning eficiente con **QLoRA (cuantizaci√≥n de 4 bits)** a trav√©s de la librer√≠a **Unsloth**, ejecutado en el cluster **HPC-UCR**.

### Caracter√≠sticas Principales

‚úÖ **Eficiencia de Memoria**: Cuantizaci√≥n de 4 bits reduce el uso de memoria en ~75%
‚úÖ **Entrenamiento R√°pido**: Optimizaciones de Unsloth aceleran el entrenamiento
‚úÖ **F√°cil Configuraci√≥n**: Scripts automatizados para setup
‚úÖ **Flexible**: Configuraci√≥n centralizada y f√°cil de modificar
‚úÖ **Reproducible**: Semillas aleatorias y configuraci√≥n documentada
‚úÖ **HPC-Ready**: Script SLURM incluido para clusters

### Especificaciones T√©cnicas

| Componente | Descripci√≥n |
|-----------|-------------|
| **Framework** | PyTorch 2.7.1, TorchVision 0.22.1, TorchAudio 2.7.1 |
| **Transformers** | HuggingFace Transformers |
| **Estrategia** | QLoRA (4-bit) + Low Rank Adapters |
| **Modelo Base** | `meta-llama/Llama-3.2-1B-Instruct` |
| **Longitud de Secuencia** | 4096 tokens |
| **Optimizador** | AdamW con warmup + cosine decay |
| **Formato de Datos** | JSONL (instruction, input, output) |
| **Infraestructura** | HPC-UCR GPU partition (A100 80GB) |
| **Evaluaci√≥n** | Eval Loss & Perplexity |

---

## üöÄ Inicio R√°pido

```bash
# 1. Clonar el repositorio
git clone <repository-url>
cd llama32_qlora

# 2. Ejecutar setup autom√°tico
bash setup.sh

# 3. Colocar tus datos de entrenamiento
# Coloca tu dataset en: data/base.jsonl

# 4. Entrenar (local)
python scripts/train_llama32_gpu.py

# O entrenar en HPC con SLURM
sbatch scripts/train_block_full_gpu.sbatch

# 5. Ejecutar inferencia
python scripts/infer_llama.py \
    --model_path outputs/llama32_qlora \
    --prompt "¬øQu√© es Python?"
```

---

## üì¶ Instalaci√≥n

### Opci√≥n 1: Setup Autom√°tico (Recomendado)

```bash
bash setup.sh
```

El script automatizado:
- ‚úÖ Verifica dependencias del sistema
- ‚úÖ Crea entorno virtual
- ‚úÖ Instala todas las dependencias
- ‚úÖ Configura estructura de directorios
- ‚úÖ Verifica instalaci√≥n de GPU/CUDA

### Opci√≥n 2: Instalaci√≥n Manual

Ver la [Gu√≠a de Instalaci√≥n Detallada](INSTALL.md) para instrucciones paso a paso.

#### Requisitos M√≠nimos

- Python 3.8+
- NVIDIA GPU con 12GB+ VRAM
- CUDA 11.8+
- 20GB de espacio en disco

#### Instalaci√≥n R√°pida

```bash
# Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

Ver [INSTALL.md](INSTALL.md) para detalles completos y troubleshooting.

---

## ‚öôÔ∏è Configuraci√≥n

### Archivo de Configuraci√≥n

Todas las configuraciones est√°n centralizadas en `config.py`:

```python
# Editar config.py para personalizar

# Modelo y datos
MODEL_NAME = "meta-llama/Llama-3.2-1B-Instruct"
DATASET_PATH = "data/base.jsonl"

# Par√°metros de entrenamiento
NUM_TRAIN_EPOCHS = 60
LEARNING_RATE = 2e-4
PER_DEVICE_TRAIN_BATCH_SIZE = 2

# Par√°metros LoRA
LORA_R = 16
LORA_ALPHA = 32
LORA_DROPOUT = 0.05
```

### Variables de Entorno

Tambi√©n puedes usar variables de entorno para override:

```bash
export MODEL="meta-llama/Llama-3.2-1B-Instruct"
export DATA="./data/mi_dataset.jsonl"
export EPOCHS=40
export OUT="./outputs/mi_modelo"

python scripts/train_llama32_gpu.py
```

### Verificar Configuraci√≥n

```bash
# Ver configuraci√≥n actual
python config.py
```

---

## üìä Formato de Datos

### Formato JSONL Requerido

Tu dataset debe estar en formato JSONL (JSON Lines) con los siguientes campos:

```jsonl
{"instruction": "Traduce al ingl√©s", "input": "Hola mundo", "output": "Hello world"}
{"instruction": "¬øQu√© es Python?", "output": "Python es un lenguaje de programaci√≥n..."}
{"instruction": "Resume este texto", "input": "Texto largo...", "output": "Resumen..."}
```

### Campos

- **`instruction`** (requerido): La instrucci√≥n o pregunta
- **`input`** (opcional): Contexto o entrada adicional
- **`output`** (requerido): La respuesta esperada

### Ejemplo de Dataset

Crea `data/base.jsonl`:

```jsonl
{"instruction": "¬øQu√© es machine learning?", "output": "Machine learning es una rama de la inteligencia artificial que permite a las computadoras aprender de datos sin ser programadas expl√≠citamente."}
{"instruction": "Traduce al ingl√©s", "input": "Buenos d√≠as", "output": "Good morning"}
{"instruction": "Resume en una frase", "input": "Python es un lenguaje de programaci√≥n de alto nivel, interpretado y de prop√≥sito general.", "output": "Python es un lenguaje vers√°til de alto nivel."}
```

### Validar Dataset

```bash
# Verificar formato del dataset
python - << 'EOF'
import json

with open('data/base.jsonl', 'r') as f:
    for i, line in enumerate(f, 1):
        try:
            data = json.loads(line)
            assert 'instruction' in data, f"L√≠nea {i}: falta 'instruction'"
            assert 'output' in data, f"L√≠nea {i}: falta 'output'"
            print(f"‚úÖ L√≠nea {i}: OK")
        except Exception as e:
            print(f"‚ùå L√≠nea {i}: {e}")
EOF
```

---

## üéØ Entrenamiento

### Entrenamiento Local

```bash
# Activar entorno virtual
source venv/bin/activate

# Entrenar con configuraci√≥n por defecto
python scripts/train_llama32_gpu.py

# O con par√°metros personalizados
EPOCHS=40 LEARNING_RATE=1e-4 python scripts/train_llama32_gpu.py
```

### Entrenamiento en HPC con SLURM

#### 1. Configurar Usuario

Edita `scripts/train_block_full_gpu.sbatch`:

```bash
# Cambiar estas l√≠neas seg√∫n tu sistema
USER_HOME="${HOME}"
PROJECT_ROOT="${USER_HOME}/llama32_qlora"

# Configurar email (opcional)
# #SBATCH --mail-user=tu.email@ejemplo.com
# #SBATCH --mail-type=END,FAIL
```

#### 2. Enviar Job

```bash
cd scripts
sbatch train_block_full_gpu.sbatch
```

#### 3. Monitorear Job

```bash
# Ver estado del job
squeue -u $USER

# Ver output en tiempo real
tail -f llama32_qlora_full_*.out

# Ver logs completos
less llama32_qlora_full_*.out
```

### Par√°metros de Entrenamiento

| Par√°metro | Valor por Defecto | Descripci√≥n |
|-----------|-------------------|-------------|
| `EPOCHS` | 60 | N√∫mero de √©pocas de entrenamiento |
| `MAX_STEPS` | 0 | Pasos m√°ximos (0 = usar √©pocas completas) |
| `LEARNING_RATE` | 2e-4 | Tasa de aprendizaje |
| `BATCH_SIZE` | 2 | Tama√±o de batch por dispositivo |
| `GRAD_ACCUM` | 4 | Pasos de acumulaci√≥n de gradientes |
| `EVAL_STEPS` | 200 | Frecuencia de evaluaci√≥n |
| `LORA_R` | 16 | Rango de LoRA |
| `LORA_ALPHA` | 32 | Alpha de LoRA |

---

## üîÆ Inferencia

### Inferencia B√°sica

```bash
python scripts/infer_llama.py \
    --model_path outputs/llama32_qlora \
    --prompt "¬øQu√© es Python?"
```

### Modo Interactivo

```bash
python scripts/infer_llama.py \
    --model_path outputs/llama32_qlora \
    --interactive
```

### Par√°metros Personalizados

```bash
python scripts/infer_llama.py \
    --model_path outputs/llama32_qlora \
    --prompt "Explica qu√© es machine learning" \
    --max_tokens 300 \
    --temperature 0.8 \
    --top_p 0.95
```

### Opciones de Inferencia

| Par√°metro | Por Defecto | Descripci√≥n |
|-----------|-------------|-------------|
| `--model_path` | (requerido) | Ruta al modelo entrenado |
| `--prompt` | None | Texto de entrada |
| `--interactive` | False | Modo interactivo |
| `--max_tokens` | 200 | M√°ximo de tokens a generar |
| `--temperature` | 0.7 | Temperatura de sampling (0=determinista) |
| `--top_p` | 0.9 | Nucleus sampling |
| `--top_k` | 50 | Top-k sampling |
| `--repetition_penalty` | 1.1 | Penalizaci√≥n por repetici√≥n |
| `--no_cuda` | False | Forzar uso de CPU |

---

## üóÇÔ∏è Estructura del Proyecto

```
llama32_qlora/
‚îú‚îÄ‚îÄ README.md                    # Este archivo
‚îú‚îÄ‚îÄ INSTALL.md                   # Gu√≠a de instalaci√≥n detallada
‚îú‚îÄ‚îÄ requirements.txt             # Dependencias de Python
‚îú‚îÄ‚îÄ config.py                    # Configuraci√≥n centralizada
‚îú‚îÄ‚îÄ setup.sh                     # Script de setup autom√°tico
‚îú‚îÄ‚îÄ .gitignore                   # Archivos ignorados por git
‚îÇ
‚îú‚îÄ‚îÄ scripts/                     # Scripts de entrenamiento e inferencia
‚îÇ   ‚îú‚îÄ‚îÄ train_llama32_gpu.py         # Script principal de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ train_block_full_gpu.sbatch  # Job SLURM para HPC
‚îÇ   ‚îî‚îÄ‚îÄ infer_llama.py               # Script de inferencia
‚îÇ
‚îú‚îÄ‚îÄ data/                        # Datos de entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ base.jsonl                   # Tu dataset (no incluido)
‚îÇ
‚îú‚îÄ‚îÄ outputs/                     # Modelos entrenados
‚îÇ   ‚îî‚îÄ‚îÄ llama32_qlora/               # Checkpoints y adapters
‚îÇ       ‚îú‚îÄ‚îÄ adapter_model.safetensors
‚îÇ       ‚îú‚îÄ‚îÄ adapter_config.json
‚îÇ       ‚îú‚îÄ‚îÄ tokenizer.json
‚îÇ       ‚îú‚îÄ‚îÄ tokenizer_config.json
‚îÇ       ‚îî‚îÄ‚îÄ training_summary.json
‚îÇ
‚îú‚îÄ‚îÄ logs/                        # Logs de entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ *.out / *.err                # Logs de SLURM
‚îÇ
‚îú‚îÄ‚îÄ models/                      # Cache de HuggingFace
‚îÇ   ‚îú‚îÄ‚îÄ hf_home/
‚îÇ   ‚îî‚îÄ‚îÄ hf_cache/
‚îÇ
‚îî‚îÄ‚îÄ venv/                        # Entorno virtual (creado por setup)
```

---

## üìà Resultados

El entrenamiento fue ejecutado por **60 √©pocas** usando QLoRA (4-bit) en una GPU NVIDIA **A100 80GB** (HPC-UCR), con un scheduler de warmup + cosine decay.

### M√©tricas Finales

| M√©trica | Valor Inicial | Valor Final | Mejora |
|---------|---------------|-------------|--------|
| **Eval Loss** | 3.08 | 1.70 | ‚Üì 45% |
| **Perplexity** | 21.74 | 5.47 | ‚Üì 75% |
| **Train Loss** | 3.22 | 0.14 | ‚Üì 96% |

### Progreso por √âpoca

| √âpoca | Train Loss | Eval Loss | Perplexity | Learning Rate |
|------:|-----------:|----------:|-----------:|--------------:|
| 1     | 3.22      | 3.08      | 21.74      | 2.66√ó10‚Åª‚Åµ    |
| 10    | 0.21      | 3.01      | 20.37      | 1.71√ó10‚Åª‚Å¥    |
| 20    | 0.18      | 2.98      | 19.68      | 1.37√ó10‚Åª‚Å¥    |
| 30    | 0.15      | 2.81      | 16.65      | 1.03√ó10‚Åª‚Å¥    |
| 40    | 0.15      | 2.67      | 14.38      | 6.88√ó10‚Åª‚Åµ    |
| 50    | 0.15      | 2.46      | 11.67      | 3.40√ó10‚Åª‚Åµ    |
| 60    | 0.14      | 1.70      | 5.47       | 4.35√ó10‚Åª‚Å∏    |

### Observaciones

- ‚úÖ **Reducci√≥n consistente** de loss y perplejidad en validaci√≥n
- ‚úÖ **Sin overfitting**: Mejora continua en set de evaluaci√≥n
- ‚úÖ **Estabilidad**: Gradient norm estable (4.09 ‚Üí 0.29)
- ‚úÖ **Convergencia**: Learning rate decae suavemente
- ‚ö° **Tiempo de entrenamiento**: ~18 horas (3 bloques √ó 6 horas en A100)

---

## üõ†Ô∏è Resoluci√≥n de Problemas

### GPU No Detectada

```bash
# Verificar GPU
nvidia-smi

# Verificar CUDA en PyTorch
python -c "import torch; print(torch.cuda.is_available())"

# Si devuelve False, reinstalar PyTorch
pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1
```

### Out of Memory (OOM)

Edita `config.py`:

```python
# Reducir batch size
PER_DEVICE_TRAIN_BATCH_SIZE = 1

# Aumentar gradient accumulation
GRADIENT_ACCUMULATION_STEPS = 8

# Reducir longitud de secuencia
MAX_SEQ_LENGTH = 2048
```

### Dataset No Encontrado

```bash
# Verificar que existe
ls -lh data/base.jsonl

# Verificar formato
head -n 3 data/base.jsonl

# Validar JSON
python -m json.tool < data/base.jsonl > /dev/null && echo "‚úÖ Valid JSON"
```

### Error al Instalar Unsloth

```bash
# Probar instalaci√≥n desde source
pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"

# O instalar componentes individualmente
pip install bitsandbytes peft
```

### Ver M√°s Troubleshooting

Consulta [INSTALL.md](INSTALL.md#troubleshooting) para soluciones detalladas.

---

## ü§ù Contribuciones

Este es un proyecto acad√©mico de la Universidad de Costa Rica. Si encuentras problemas o tienes sugerencias:

1. Documenta el problema claramente
2. Incluye pasos para reproducir
3. Adjunta logs relevantes
4. Especifica tu entorno (OS, Python, CUDA, GPU)

---

## üìù Licencia

Este proyecto es de uso acad√©mico. El dataset no est√° incluido por razones de privacidad y licencia.

---

## üë©‚Äçüíª Autor

**Alison Lobo Salas**
Universidad de Costa Rica (UCR)
üìç San Jos√©, Costa Rica

---

## üôè Agradecimientos

- **HPC-UCR**: Por proveer la infraestructura computacional
- **Unsloth**: Por la librer√≠a de entrenamiento eficiente
- **HuggingFace**: Por Transformers y el ecosistema de modelos
- **Meta**: Por el modelo LLaMA 3.2

---

## üìö Referencias

- [Unsloth Documentation](https://github.com/unslothai/unsloth)
- [QLoRA Paper](https://arxiv.org/abs/2305.14314)
- [LLaMA 3.2 Model Card](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers)

---

## üìã Changelog

### v2.0.0 (2025-12-04)
- ‚ú® Configuraci√≥n centralizada con `config.py`
- ‚ú® Script de setup autom√°tico
- ‚ú® Documentaci√≥n mejorada y m√°s clara
- ‚ú® Mejor manejo de errores
- ‚ú® Rutas configurables (no hardcodeadas)
- ‚ú® Modo interactivo de inferencia
- ‚ú® Gu√≠a de instalaci√≥n detallada
- üêõ Correcciones de paths y compatibilidad
- üìö README reorganizado y m√°s accesible

### v1.0.0
- üéâ Versi√≥n inicial del proyecto
- ‚úÖ Entrenamiento funcional con QLoRA
- ‚úÖ Scripts de inferencia b√°sicos

---

**¬øPreguntas?** Consulta [INSTALL.md](INSTALL.md) para m√°s detalles o revisa los comentarios en el c√≥digo.
